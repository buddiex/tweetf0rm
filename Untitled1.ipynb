{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/stephenhky/PyShortTextCategorization/tree/b298d3ce7d06a9b4e0f7d32f27bab66064ba7afa\n",
    "# sudo yum install git-lfs\n",
    "# curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.rpm.sh | sudo bash\n",
    "# https://github.com/3Top/word2vec-api#where-to-get-a-pretrained-models\n",
    "\n",
    "import argparse, os, re, string, json, gensim, pickle\n",
    "import config as conf\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.utils import deaccent, decode_htmlentities, lemmatize\n",
    "from shorttext.utils.classification_exceptions import Word2VecModelNotExistException, AlgorithmNotExistException\n",
    "import shorttext.classifiers.embed.sumvec.SumEmbedVecClassification as sumwv\n",
    "import shorttext.classifiers.embed.nnlib.VarNNEmbedVecClassification as auto\n",
    "import shorttext.classifiers.embed.nnlib.VarNNEmbedVecClassification as cnn\n",
    "\n",
    "def preprocess_text(tweet):\n",
    "    tweet = re.sub(r\"(?:\\https|http?\\://)\\S+\", \"\", tweet) # remove urls\n",
    "    tweet = decode_htmlentities(tweet)\n",
    "    tweet = deaccent(tweet)\n",
    "    tweet = tweet.encode('ascii', 'ignore')  # To prevent UnicodeDecodeErrors later on\n",
    "    tweet = tweet.split()\n",
    "    tweet = lemmatize(' '.join(tweet), re.compile('(NN|JJ)'), stopwords=stops, min_length=3, max_length=15)\n",
    "    tweet = [word.split('/')[0] for word in tweet]\n",
    "    return tweet\n",
    "\n",
    "\n",
    "stops = set(stopwords.words('english')).union(set(string.punctuation) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w2vmodel = gensim.models.KeyedVectors.load_word2vec_format('data/models/w2v.twitter.27B.100d.txt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializes class...\n",
      "Instantiating classifier...\n",
      "Train model...\n",
      "Save model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function keys>"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Trainer():\n",
    "    \n",
    "    def __init__(self, algo='sumword2vec', ngram=2, vecsize=100):\n",
    "        self.vecsize = vecsize\n",
    "#         self.w2vmodel = self.load_pre_trained_twt_w2v(self.vecsize)\n",
    "        self.w2vmodel = w2vmodel\n",
    "        self.ngram = ngram\n",
    "        self.algo = algo\n",
    "        self.ft_vec = False\n",
    "\n",
    "    def load_pre_trained_twt_w2v(self, vecsize):\n",
    "        print ('loading pretrained word2vec model... this can take a while')\n",
    "        return KeyedVectors.load_word2vec_format(join(conf.W2V_PRETRAINED_TWITTER_MODEL.format(vecsize)))\n",
    "                                             \n",
    "    def get_algo_class(self):\n",
    "        # initialize instance\n",
    "        print \"Instantiating classifier...\"\n",
    "        if self.algo=='sumword2vec':\n",
    "            classifier = sumwv.SumEmbeddedVecClassifier(self.w2vmodel, vecsize=self.vecsize)\n",
    "        elif self.algo=='autoencoder':\n",
    "            classifier = auto.AutoEncoderWord2VecClassifier(self.w2vmodel, vecsize=self.vecsize)\n",
    "        elif self.algo=='cnn':\n",
    "            classifier = cnn.CNNEmbeddedVecClassifier(self.w2vmodel, vecsize=self.vecsize, n_gram=self.ngram)\n",
    "#         classifier.savemodel(join(conf.MODELS_FOLDER,'clsf_'+self.algo+'_model'))\n",
    "        return classifier\n",
    "    \n",
    "    def train_model(self, training_dict):\n",
    "        print \"Initializes class...\"\n",
    "        clsf = self.get_algo_class()\n",
    "        print \"Train model...\"\n",
    "        clsf.train(training_dict) \n",
    "        print \"Save model...\"\n",
    "        clsf.savemodel(join(conf.MODELS_FOLDER,'clsf_'+self.algo+'_model'))\n",
    "        return clsf\n",
    "        \n",
    "# def predict(df):\n",
    "#     return df.\n",
    "def save_json(in_dict, filename):\n",
    "    with open('train_data.json', 'w') as outfile:\n",
    "        json.dump(out_dict, outfile, indent=2)\n",
    "\n",
    "def load_json(file_name):\n",
    "    with open(file_name) as outfile:\n",
    "        in_dict = json.load(outfile)\n",
    "    return in_dict\n",
    "\n",
    "# save_json(out_dict, 'train_data.json')\n",
    "# train_w2v_feature_vec(train_dict, w2vmodel,'sumword2vec')\n",
    "train_dict = load_json('train_data.json')\n",
    "out_dic = {}\n",
    "for k,v in train_dict.items():\n",
    "    out_dic[k]=[preprocess_text(i) for i in v] \n",
    "    \n",
    "tt = Trainer()\n",
    "classifier = tt.train_model(train_dict)\n",
    "classifier.addvec.keys()\n",
    "# # json.load?\n",
    "# scoredict = classifier.score('i love basketball')\n",
    "# toplabel, topscoreniger = max(scoredict.items(), key=lambda item: item[1])\n",
    "# scoredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0xc86dd10>"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.wvmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://tech.reputation.com/semi-supervised-learning-multi-label-text-classification/\n",
    "import scipy\n",
    "# from gensim.corpora import Dictionary\n",
    "\n",
    "\n",
    "# processed_dic = {}\n",
    "# for k,v in train_dict.items():\n",
    "#     processed_dic[k]=[preprocess_text(i) for i in v] \n",
    "\n",
    "# vocab = []\n",
    "# for key, tokens in processed_dic.items():\n",
    "#     for token in tokens:\n",
    "#         for word in token:\n",
    "#             vocab.append(word)\n",
    "\n",
    "\n",
    "# for i in processed_dic.itervalues():\n",
    "#     tweet_processed.extend([k for k in i])\n",
    "dictionay = Dictionary(tweet_processed)\n",
    "\n",
    "correlation_matrix = scipy.sparse.identity(len(vocab), format=\"dok\")\n",
    "for tokens in dictionay.values():\n",
    "    similar_words = []\n",
    "    try:\n",
    "        similar_words = [x[0] for x in w2vmodel.most_similar(tokens.lower(), topn=5) if x[1] > 0.5]\n",
    "    except:\n",
    "#         raise\n",
    "        pass\n",
    "    for similar_word in similar_words:\n",
    "        if similar_word in vocab:\n",
    "            correlation_matrix[dictionay.token2id[word], dictionay.token2id[similar_word]] = 1\n",
    "            \n",
    "#         term_frequency_vector += term_frequency_vector * correlation_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: y: command not found\r\n"
     ]
    }
   ],
   "source": [
    "# https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "# https://www.bonaccorso.eu/2016/08/02/reuters-21578-text-classification-with-gensim-and-keras/\n",
    "# http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/\n",
    "!conda install -c conda-forge jupyterlab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
