{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tweetf0rm.handler.oracle_handler import OracleHandler\n",
    "import langid\n",
    "import re\n",
    "\n",
    "def remove_url(documents):\n",
    "    return [(doc[0],re.sub(r\"(?:\\@|http?\\://)\\S+\", \"\", doc[1])) for doc in documents]\n",
    "\n",
    "def filter_lang(lang, documents):\n",
    "    return (doc for doc in documents if langid.classify(doc[1])[0] == lang)\n",
    "\n",
    "db = OracleHandler()\n",
    "txt_list = [i for i in db.query_db(\"\"\"\n",
    "                                    select user_handle, text\n",
    "                                    from tweets_timeline\n",
    "                                    where lang in ('en', 'und') \n",
    "                                    and user_handle = 'osayamenomigie'\"\"\") ]\n",
    "\n",
    "data = remove_url(txt_list[0:3])\n",
    "data = filter_lang('en', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_handle</th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>osayamenomigie</td>\n",
       "      <td>rt cant watch without smiling funny simple wel...</td>\n",
       "      <td>[rt, cant, watch, without, smiling, funny, sim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_handle                                               text  \\\n",
       "0  osayamenomigie  rt cant watch without smiling funny simple wel...   \n",
       "\n",
       "                                           processed  \n",
       "0  [rt, cant, watch, without, smiling, funny, sim...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langid\n",
    "import re\n",
    "import pandas as pd\n",
    "import config\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy.engine.url as url\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "db_eng = create_engine(config.SQLALCHEMY_DATABASE_URI, encoding='utf8')\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# from six import iteritems\n",
    "\n",
    "# # collect statistics about all tokens\n",
    "# dictionary = corpora.Dictionary(line.lower().split() for line in open('datasets/mycorpus.txt'))\n",
    "\n",
    "# # remove stop words and words that appear only once\n",
    "# stop_ids = [dictionary.token2id[stopword] for stopword in stoplist \n",
    "#             if stopword in dictionary.token2id]\n",
    "# once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "\n",
    "# # remove stop words and words that appear only once\n",
    "# dictionary.filter_tokens(stop_ids + once_ids)\n",
    "\n",
    "# # remove gaps in id sequence after words that were removed\n",
    "# dictionary.compactify()\n",
    "# print(dictionary)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import string\n",
    "\n",
    "# exclude = string.punctuation\n",
    "# exclude = re.sub('<|>', '', exclude)  # To keep our <tags> intact\n",
    "# exclude = set(exclude)\n",
    "\n",
    "\n",
    "# FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "# def hashtag(text):\n",
    "#     text = text.group()\n",
    "#     hashtag_body = text[1:]\n",
    "#     if hashtag_body.isupper():\n",
    "#         result = \"<hashtag> {} <allcaps>\".format(hashtag_body)\n",
    "#     else:\n",
    "#         result = \" \".join([\"<hashtag>\"] + re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n",
    "#     return result\n",
    "\n",
    "# def allcaps(text):\n",
    "#     text = text.group()\n",
    "#     return text.lower() + \" <allcaps> \"\n",
    "\n",
    "\n",
    "# def preprocess_tweet(text):\n",
    "#     # Different regex parts for smiley faces\n",
    "#     eyes = r\"[8:=;]\"\n",
    "#     nose = r\"['`\\-]?\"\n",
    "\n",
    "#     # function so code less repetitive\n",
    "#     def re_sub(pattern, repl):\n",
    "#         return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "#     text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "#     text = re_sub(r\"/\",\" / \")\n",
    "#     text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "#     text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "#     text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "#     text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "#     text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "#     text = re_sub(r\"<3\",\"<heart>\")\n",
    "#     text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \" <number> \")\n",
    "#     text = re_sub(r\"#\\S+\", hashtag)\n",
    "#     text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "#     text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(r\"(?:\\@|https|http?\\://)\\S+\", \"\", tweet) # remove urls\n",
    "    tweet = \" \".join([i for i in tweet.lower().split() if i not in stop]) #tokenize and remove stop words\n",
    "    tweet = ''.join(ch for ch in tweet if ch not in exclude)# remove more words\n",
    "    tweet = \" \".join(lemma.lemmatize(word) for word in tweet.split())\n",
    "    return tweet\n",
    "\n",
    "def filter_lang(text,lang='en'):\n",
    "    return  langid.classify(text)[0] == lang\n",
    "\n",
    "# db = OracleHandler()\n",
    "sql = \"\"\"\n",
    "        select user_handle, text\n",
    "        from tweets_timeline\n",
    "        where lang in ('en', 'und') \n",
    "        and user_handle = 'osayamenomigie'\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sql, db_eng)\n",
    "df2 = df.copy()\n",
    "df2 = df2[df2.apply(lambda row: filter_lang(row['text']), axis=1)] #filter for english\n",
    "df2 = df2.groupby(['user_handle'])['text'].apply(lambda x: ','.join(x)).reset_index()\n",
    "df2['text'] = df2['text'].map(clean_tweet)# remove urls\n",
    "df2['processed']  = df2.text.str.split()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-[2017-05-04 18:01:24,628][dictionary][add_documents][116]: adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO-[2017-05-04 18:01:24,637][dictionary][add_documents][123]: built Dictionary(3229 unique tokens: ['rt', 'cant', 'watch', 'without', 'smiling']...) from 1 documents (total 6705 corpus positions)\n",
      "INFO-[2017-05-04 18:01:24,645][ldamodel][init_dir_prior][350]: using symmetric alpha at 0.1\n",
      "INFO-[2017-05-04 18:01:24,646][ldamodel][init_dir_prior][350]: using symmetric eta at 0.0003096934035305048\n",
      "INFO-[2017-05-04 18:01:24,648][ldamodel][__init__][304]: using serial LDA version on this node\n",
      "INFO-[2017-05-04 18:01:25,162][ldamodel][update][610]: running online LDA training, 10 topics, 50 passes over the supplied corpus of 1 documents, updating model once every 1 documents, evaluating perplexity every 1 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO-[2017-05-04 18:01:26,198][ldamodel][log_perplexity][527]: -13.983 per-word bound, 16187.9 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:26,200][ldamodel][update][646]: PROGRESS: pass 0, at document #1/1\n",
      "INFO-[2017-05-04 18:01:26,261][ldamodel][show_topics][798]: topic #6 (0.100): 0.007*\"u\" + 0.004*\"data\" + 0.003*\"week\" + 0.003*\"get\" + 0.003*\"nigeria\" + 0.003*\"mention\" + 0.003*\"go\" + 0.003*\"need\" + 0.003*\"new\" + 0.003*\"amp\"\n",
      "INFO-[2017-05-04 18:01:26,263][ldamodel][show_topics][798]: topic #0 (0.100): 0.009*\"u\" + 0.004*\"data\" + 0.004*\"one\" + 0.004*\"nigeria\" + 0.004*\"it\" + 0.003*\"go\" + 0.003*\"week\" + 0.003*\"amp\" + 0.003*\"new\" + 0.003*\"people\"\n",
      "INFO-[2017-05-04 18:01:26,265][ldamodel][show_topics][798]: topic #3 (0.100): 0.005*\"u\" + 0.005*\"week\" + 0.004*\"data\" + 0.003*\"nigeria\" + 0.003*\"like\" + 0.003*\"get\" + 0.003*\"rt\" + 0.003*\"need\" + 0.002*\"see\" + 0.002*\"life\"\n",
      "INFO-[2017-05-04 18:01:26,268][ldamodel][show_topics][798]: topic #2 (0.100): 0.007*\"u\" + 0.004*\"week\" + 0.004*\"get\" + 0.004*\"one\" + 0.004*\"it\" + 0.004*\"data\" + 0.004*\"amp\" + 0.003*\"people\" + 0.003*\"go\" + 0.003*\"new\"\n",
      "INFO-[2017-05-04 18:01:26,270][ldamodel][show_topics][798]: topic #8 (0.100): 0.007*\"u\" + 0.004*\"get\" + 0.004*\"one\" + 0.004*\"week\" + 0.004*\"data\" + 0.004*\"work\" + 0.003*\"way\" + 0.003*\"life\" + 0.003*\"rt\" + 0.003*\"see\"\n",
      "INFO-[2017-05-04 18:01:26,273][ldamodel][do_mstep][701]: topic diff=2.874715, rho=1.000000\n",
      "INFO-[2017-05-04 18:01:26,712][ldamodel][log_perplexity][527]: -10.763 per-word bound, 1737.4 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:26,715][ldamodel][update][646]: PROGRESS: pass 1, at document #1/1\n",
      "INFO-[2017-05-04 18:01:26,775][ldamodel][show_topics][798]: topic #8 (0.100): 0.008*\"u\" + 0.005*\"get\" + 0.004*\"week\" + 0.004*\"one\" + 0.004*\"rt\" + 0.004*\"data\" + 0.004*\"work\" + 0.004*\"life\" + 0.004*\"way\" + 0.003*\"see\"\n",
      "INFO-[2017-05-04 18:01:26,777][ldamodel][show_topics][798]: topic #5 (0.100): 0.005*\"u\" + 0.003*\"week\" + 0.003*\"like\" + 0.003*\"one\" + 0.003*\"data\" + 0.002*\"nigeria\" + 0.002*\"mention\" + 0.002*\"get\" + 0.002*\"rt\" + 0.002*\"life\"\n",
      "INFO-[2017-05-04 18:01:26,778][ldamodel][show_topics][798]: topic #4 (0.100): 0.004*\"u\" + 0.002*\"week\" + 0.002*\"get\" + 0.002*\"like\" + 0.002*\"rt\" + 0.002*\"data\" + 0.002*\"one\" + 0.002*\"go\" + 0.002*\"nigeria\" + 0.002*\"it\"\n",
      "INFO-[2017-05-04 18:01:26,780][ldamodel][show_topics][798]: topic #1 (0.100): 0.006*\"u\" + 0.003*\"data\" + 0.003*\"nigeria\" + 0.003*\"get\" + 0.003*\"new\" + 0.002*\"see\" + 0.002*\"one\" + 0.002*\"life\" + 0.002*\"need\" + 0.002*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:26,781][ldamodel][show_topics][798]: topic #7 (0.100): 0.004*\"u\" + 0.003*\"data\" + 0.003*\"like\" + 0.003*\"get\" + 0.003*\"one\" + 0.002*\"rt\" + 0.002*\"make\" + 0.002*\"work\" + 0.002*\"need\" + 0.002*\"go\"\n",
      "INFO-[2017-05-04 18:01:26,782][ldamodel][do_mstep][701]: topic diff=1.334550, rho=0.577350\n",
      "INFO-[2017-05-04 18:01:27,173][ldamodel][log_perplexity][527]: -9.611 per-word bound, 782.2 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:27,175][ldamodel][update][646]: PROGRESS: pass 2, at document #1/1\n",
      "INFO-[2017-05-04 18:01:27,214][ldamodel][show_topics][798]: topic #5 (0.100): 0.003*\"u\" + 0.002*\"week\" + 0.002*\"like\" + 0.002*\"one\" + 0.002*\"data\" + 0.002*\"nigeria\" + 0.002*\"mention\" + 0.002*\"get\" + 0.002*\"rt\" + 0.001*\"life\"\n",
      "INFO-[2017-05-04 18:01:27,216][ldamodel][show_topics][798]: topic #6 (0.100): 0.003*\"u\" + 0.002*\"data\" + 0.001*\"week\" + 0.001*\"get\" + 0.001*\"nigeria\" + 0.001*\"mention\" + 0.001*\"go\" + 0.001*\"need\" + 0.001*\"new\" + 0.001*\"amp\"\n",
      "INFO-[2017-05-04 18:01:27,217][ldamodel][show_topics][798]: topic #2 (0.100): 0.006*\"u\" + 0.004*\"get\" + 0.004*\"week\" + 0.003*\"one\" + 0.003*\"data\" + 0.003*\"it\" + 0.003*\"amp\" + 0.003*\"like\" + 0.003*\"people\" + 0.003*\"new\"\n",
      "INFO-[2017-05-04 18:01:27,218][ldamodel][show_topics][798]: topic #4 (0.100): 0.003*\"u\" + 0.002*\"week\" + 0.002*\"get\" + 0.002*\"like\" + 0.001*\"rt\" + 0.001*\"data\" + 0.001*\"one\" + 0.001*\"go\" + 0.001*\"nigeria\" + 0.001*\"it\"\n",
      "INFO-[2017-05-04 18:01:27,220][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.004*\"get\" + 0.004*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:27,221][ldamodel][do_mstep][701]: topic diff=1.021717, rho=0.500000\n",
      "INFO-[2017-05-04 18:01:27,554][ldamodel][log_perplexity][527]: -8.974 per-word bound, 502.9 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:27,556][ldamodel][update][646]: PROGRESS: pass 3, at document #1/1\n",
      "INFO-[2017-05-04 18:01:27,597][ldamodel][show_topics][798]: topic #7 (0.100): 0.002*\"u\" + 0.002*\"data\" + 0.001*\"like\" + 0.001*\"get\" + 0.001*\"one\" + 0.001*\"rt\" + 0.001*\"make\" + 0.001*\"work\" + 0.001*\"need\" + 0.001*\"go\"\n",
      "INFO-[2017-05-04 18:01:27,599][ldamodel][show_topics][798]: topic #2 (0.100): 0.005*\"u\" + 0.003*\"get\" + 0.003*\"week\" + 0.003*\"one\" + 0.003*\"data\" + 0.003*\"it\" + 0.002*\"amp\" + 0.002*\"like\" + 0.002*\"people\" + 0.002*\"new\"\n",
      "INFO-[2017-05-04 18:01:27,600][ldamodel][show_topics][798]: topic #8 (0.100): 0.005*\"u\" + 0.004*\"get\" + 0.003*\"week\" + 0.003*\"one\" + 0.003*\"rt\" + 0.003*\"data\" + 0.003*\"work\" + 0.003*\"life\" + 0.002*\"way\" + 0.002*\"see\"\n",
      "INFO-[2017-05-04 18:01:27,601][ldamodel][show_topics][798]: topic #5 (0.100): 0.002*\"u\" + 0.001*\"week\" + 0.001*\"like\" + 0.001*\"one\" + 0.001*\"data\" + 0.001*\"nigeria\" + 0.001*\"mention\" + 0.001*\"get\" + 0.001*\"rt\" + 0.001*\"life\"\n",
      "INFO-[2017-05-04 18:01:27,603][ldamodel][show_topics][798]: topic #6 (0.100): 0.002*\"u\" + 0.001*\"data\" + 0.001*\"week\" + 0.001*\"get\" + 0.001*\"nigeria\" + 0.001*\"mention\" + 0.001*\"go\" + 0.001*\"need\" + 0.001*\"new\" + 0.001*\"amp\"\n",
      "INFO-[2017-05-04 18:01:27,604][ldamodel][do_mstep][701]: topic diff=0.702714, rho=0.447214\n",
      "INFO-[2017-05-04 18:01:27,985][ldamodel][log_perplexity][527]: -8.735 per-word bound, 426.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:27,987][ldamodel][update][646]: PROGRESS: pass 4, at document #1/1\n",
      "INFO-[2017-05-04 18:01:28,141][ldamodel][show_topics][798]: topic #5 (0.100): 0.002*\"u\" + 0.001*\"week\" + 0.001*\"like\" + 0.001*\"one\" + 0.001*\"data\" + 0.001*\"nigeria\" + 0.001*\"mention\" + 0.001*\"get\" + 0.001*\"rt\" + 0.001*\"life\"\n",
      "INFO-[2017-05-04 18:01:28,143][ldamodel][show_topics][798]: topic #7 (0.100): 0.001*\"u\" + 0.001*\"data\" + 0.001*\"like\" + 0.001*\"get\" + 0.001*\"one\" + 0.001*\"rt\" + 0.001*\"make\" + 0.001*\"work\" + 0.001*\"need\" + 0.001*\"go\"\n",
      "INFO-[2017-05-04 18:01:28,144][ldamodel][show_topics][798]: topic #4 (0.100): 0.001*\"u\" + 0.001*\"week\" + 0.001*\"get\" + 0.001*\"like\" + 0.001*\"rt\" + 0.001*\"data\" + 0.001*\"one\" + 0.001*\"go\" + 0.001*\"nigeria\" + 0.001*\"it\"\n",
      "INFO-[2017-05-04 18:01:28,145][ldamodel][show_topics][798]: topic #6 (0.100): 0.001*\"u\" + 0.001*\"data\" + 0.001*\"week\" + 0.001*\"get\" + 0.001*\"nigeria\" + 0.001*\"mention\" + 0.001*\"go\" + 0.001*\"need\" + 0.001*\"new\" + 0.001*\"amp\"\n",
      "INFO-[2017-05-04 18:01:28,146][ldamodel][show_topics][798]: topic #1 (0.100): 0.002*\"u\" + 0.001*\"data\" + 0.001*\"nigeria\" + 0.001*\"get\" + 0.001*\"new\" + 0.001*\"see\" + 0.001*\"one\" + 0.001*\"life\" + 0.001*\"need\" + 0.001*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:28,148][ldamodel][do_mstep][701]: topic diff=0.489869, rho=0.408248\n",
      "INFO-[2017-05-04 18:01:28,557][ldamodel][log_perplexity][527]: -8.617 per-word bound, 392.6 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:28,559][ldamodel][update][646]: PROGRESS: pass 5, at document #1/1\n",
      "INFO-[2017-05-04 18:01:28,689][ldamodel][show_topics][798]: topic #2 (0.100): 0.003*\"u\" + 0.002*\"get\" + 0.002*\"week\" + 0.002*\"one\" + 0.001*\"data\" + 0.001*\"it\" + 0.001*\"amp\" + 0.001*\"like\" + 0.001*\"people\" + 0.001*\"new\"\n",
      "INFO-[2017-05-04 18:01:28,692][ldamodel][show_topics][798]: topic #6 (0.100): 0.001*\"u\" + 0.001*\"data\" + 0.001*\"week\" + 0.001*\"get\" + 0.001*\"nigeria\" + 0.001*\"mention\" + 0.001*\"go\" + 0.001*\"need\" + 0.001*\"new\" + 0.001*\"amp\"\n",
      "INFO-[2017-05-04 18:01:28,694][ldamodel][show_topics][798]: topic #4 (0.100): 0.001*\"u\" + 0.001*\"week\" + 0.001*\"get\" + 0.001*\"like\" + 0.001*\"rt\" + 0.001*\"data\" + 0.001*\"one\" + 0.001*\"go\" + 0.001*\"nigeria\" + 0.001*\"it\"\n",
      "INFO-[2017-05-04 18:01:28,696][ldamodel][show_topics][798]: topic #5 (0.100): 0.001*\"u\" + 0.001*\"week\" + 0.001*\"like\" + 0.001*\"one\" + 0.001*\"data\" + 0.001*\"nigeria\" + 0.001*\"mention\" + 0.001*\"get\" + 0.001*\"rt\" + 0.001*\"life\"\n",
      "INFO-[2017-05-04 18:01:28,697][ldamodel][show_topics][798]: topic #7 (0.100): 0.001*\"u\" + 0.001*\"data\" + 0.001*\"like\" + 0.001*\"get\" + 0.001*\"one\" + 0.001*\"rt\" + 0.001*\"make\" + 0.001*\"work\" + 0.001*\"need\" + 0.001*\"go\"\n",
      "INFO-[2017-05-04 18:01:28,699][ldamodel][do_mstep][701]: topic diff=0.340530, rho=0.377964\n",
      "INFO-[2017-05-04 18:01:29,086][ldamodel][log_perplexity][527]: -8.556 per-word bound, 376.3 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:29,088][ldamodel][update][646]: PROGRESS: pass 6, at document #1/1\n",
      "INFO-[2017-05-04 18:01:29,217][ldamodel][show_topics][798]: topic #1 (0.100): 0.001*\"u\" + 0.001*\"data\" + 0.001*\"nigeria\" + 0.001*\"get\" + 0.001*\"new\" + 0.001*\"see\" + 0.001*\"one\" + 0.001*\"life\" + 0.001*\"need\" + 0.001*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:29,219][ldamodel][show_topics][798]: topic #6 (0.100): 0.001*\"u\" + 0.001*\"data\" + 0.001*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:29,222][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:29,224][ldamodel][show_topics][798]: topic #7 (0.100): 0.001*\"u\" + 0.001*\"data\" + 0.001*\"like\" + 0.001*\"get\" + 0.001*\"one\" + 0.001*\"rt\" + 0.001*\"make\" + 0.001*\"work\" + 0.001*\"need\" + 0.001*\"go\"\n",
      "INFO-[2017-05-04 18:01:29,226][ldamodel][show_topics][798]: topic #2 (0.100): 0.002*\"u\" + 0.001*\"get\" + 0.001*\"week\" + 0.001*\"one\" + 0.001*\"data\" + 0.001*\"it\" + 0.001*\"amp\" + 0.001*\"like\" + 0.001*\"people\" + 0.001*\"new\"\n",
      "INFO-[2017-05-04 18:01:29,228][ldamodel][do_mstep][701]: topic diff=0.236870, rho=0.353553\n",
      "INFO-[2017-05-04 18:01:29,665][ldamodel][log_perplexity][527]: -8.523 per-word bound, 368.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:29,666][ldamodel][update][646]: PROGRESS: pass 7, at document #1/1\n",
      "INFO-[2017-05-04 18:01:29,825][ldamodel][show_topics][798]: topic #3 (0.100): 0.001*\"u\" + 0.001*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:29,827][ldamodel][show_topics][798]: topic #8 (0.100): 0.002*\"u\" + 0.001*\"get\" + 0.001*\"week\" + 0.001*\"one\" + 0.001*\"rt\" + 0.001*\"data\" + 0.001*\"work\" + 0.001*\"life\" + 0.001*\"way\" + 0.001*\"see\"\n",
      "INFO-[2017-05-04 18:01:29,829][ldamodel][show_topics][798]: topic #9 (0.100): 0.001*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:29,832][ldamodel][show_topics][798]: topic #2 (0.100): 0.001*\"u\" + 0.001*\"get\" + 0.001*\"week\" + 0.001*\"one\" + 0.001*\"data\" + 0.001*\"it\" + 0.001*\"amp\" + 0.001*\"like\" + 0.001*\"people\" + 0.001*\"new\"\n",
      "INFO-[2017-05-04 18:01:29,833][ldamodel][show_topics][798]: topic #7 (0.100): 0.001*\"u\" + 0.001*\"data\" + 0.001*\"like\" + 0.001*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:29,835][ldamodel][do_mstep][701]: topic diff=0.165382, rho=0.333333\n",
      "INFO-[2017-05-04 18:01:30,279][ldamodel][log_perplexity][527]: -8.506 per-word bound, 363.5 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:30,281][ldamodel][update][646]: PROGRESS: pass 8, at document #1/1\n",
      "INFO-[2017-05-04 18:01:30,412][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:30,414][ldamodel][show_topics][798]: topic #8 (0.100): 0.001*\"u\" + 0.001*\"get\" + 0.001*\"week\" + 0.001*\"one\" + 0.001*\"rt\" + 0.001*\"data\" + 0.001*\"work\" + 0.001*\"life\" + 0.001*\"way\" + 0.001*\"see\"\n",
      "INFO-[2017-05-04 18:01:30,416][ldamodel][show_topics][798]: topic #2 (0.100): 0.001*\"u\" + 0.001*\"get\" + 0.001*\"week\" + 0.001*\"one\" + 0.001*\"data\" + 0.001*\"it\" + 0.001*\"amp\" + 0.001*\"like\" + 0.001*\"people\" + 0.001*\"new\"\n",
      "INFO-[2017-05-04 18:01:30,417][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:30,418][ldamodel][show_topics][798]: topic #6 (0.100): 0.001*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:30,419][ldamodel][do_mstep][701]: topic diff=0.116135, rho=0.316228\n",
      "INFO-[2017-05-04 18:01:30,816][ldamodel][log_perplexity][527]: -8.496 per-word bound, 361.1 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:30,818][ldamodel][update][646]: PROGRESS: pass 9, at document #1/1\n",
      "INFO-[2017-05-04 18:01:30,937][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:30,939][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:30,941][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:30,942][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:30,943][ldamodel][show_topics][798]: topic #8 (0.100): 0.001*\"u\" + 0.001*\"get\" + 0.001*\"week\" + 0.001*\"one\" + 0.001*\"rt\" + 0.001*\"data\" + 0.001*\"work\" + 0.001*\"life\" + 0.001*\"way\" + 0.001*\"see\"\n",
      "INFO-[2017-05-04 18:01:30,944][ldamodel][do_mstep][701]: topic diff=0.082121, rho=0.301511\n",
      "INFO-[2017-05-04 18:01:31,326][ldamodel][log_perplexity][527]: -8.491 per-word bound, 359.8 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:31,328][ldamodel][update][646]: PROGRESS: pass 10, at document #1/1\n",
      "INFO-[2017-05-04 18:01:31,476][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:31,479][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:31,481][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:31,483][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:31,486][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:31,488][ldamodel][do_mstep][701]: topic diff=0.058511, rho=0.288675\n",
      "INFO-[2017-05-04 18:01:31,923][ldamodel][log_perplexity][527]: -8.488 per-word bound, 359.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:31,924][ldamodel][update][646]: PROGRESS: pass 11, at document #1/1\n",
      "INFO-[2017-05-04 18:01:32,072][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:32,075][ldamodel][show_topics][798]: topic #8 (0.100): 0.001*\"u\" + 0.001*\"get\" + 0.001*\"week\" + 0.001*\"one\" + 0.001*\"rt\" + 0.001*\"data\" + 0.001*\"work\" + 0.001*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:32,076][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:32,078][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:32,080][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:32,082][ldamodel][do_mstep][701]: topic diff=0.042019, rho=0.277350\n",
      "INFO-[2017-05-04 18:01:32,508][ldamodel][log_perplexity][527]: -8.486 per-word bound, 358.6 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:32,511][ldamodel][update][646]: PROGRESS: pass 12, at document #1/1\n",
      "INFO-[2017-05-04 18:01:32,654][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:32,656][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:32,658][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:32,660][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:32,662][ldamodel][show_topics][798]: topic #8 (0.100): 0.001*\"u\" + 0.001*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:32,664][ldamodel][do_mstep][701]: topic diff=0.030417, rho=0.267261\n",
      "INFO-[2017-05-04 18:01:33,123][ldamodel][log_perplexity][527]: -8.485 per-word bound, 358.4 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:33,125][ldamodel][update][646]: PROGRESS: pass 13, at document #1/1\n",
      "INFO-[2017-05-04 18:01:33,344][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:33,346][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:33,348][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:33,350][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:33,352][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:33,354][ldamodel][do_mstep][701]: topic diff=0.022195, rho=0.258199\n",
      "INFO-[2017-05-04 18:01:33,824][ldamodel][log_perplexity][527]: -8.485 per-word bound, 358.2 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:33,826][ldamodel][update][646]: PROGRESS: pass 14, at document #1/1\n",
      "INFO-[2017-05-04 18:01:33,949][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:33,952][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:33,954][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:33,956][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:33,958][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:33,960][ldamodel][do_mstep][701]: topic diff=0.016322, rho=0.250000\n",
      "INFO-[2017-05-04 18:01:34,473][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.1 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:34,475][ldamodel][update][646]: PROGRESS: pass 15, at document #1/1\n",
      "INFO-[2017-05-04 18:01:34,635][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:34,638][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:34,639][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:34,641][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:34,644][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:34,645][ldamodel][do_mstep][701]: topic diff=0.012097, rho=0.242536\n",
      "INFO-[2017-05-04 18:01:35,080][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.1 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:35,081][ldamodel][update][646]: PROGRESS: pass 16, at document #1/1\n",
      "INFO-[2017-05-04 18:01:35,246][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:35,248][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:35,250][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:35,252][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:35,254][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:35,256][ldamodel][do_mstep][701]: topic diff=0.009033, rho=0.235702\n",
      "INFO-[2017-05-04 18:01:35,632][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.1 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:35,634][ldamodel][update][646]: PROGRESS: pass 17, at document #1/1\n",
      "INFO-[2017-05-04 18:01:35,832][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:35,835][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:35,836][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:35,838][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:35,839][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:35,841][ldamodel][do_mstep][701]: topic diff=0.006795, rho=0.229416\n",
      "INFO-[2017-05-04 18:01:36,278][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:36,280][ldamodel][update][646]: PROGRESS: pass 18, at document #1/1\n",
      "INFO-[2017-05-04 18:01:36,398][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:36,401][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:36,402][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:36,404][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:36,406][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:36,408][ldamodel][do_mstep][701]: topic diff=0.005148, rho=0.223607\n",
      "INFO-[2017-05-04 18:01:36,818][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:36,819][ldamodel][update][646]: PROGRESS: pass 19, at document #1/1\n",
      "INFO-[2017-05-04 18:01:36,936][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:36,939][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:36,940][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:36,942][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:36,943][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:36,944][ldamodel][do_mstep][701]: topic diff=0.003927, rho=0.218218\n",
      "INFO-[2017-05-04 18:01:37,349][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:37,351][ldamodel][update][646]: PROGRESS: pass 20, at document #1/1\n",
      "INFO-[2017-05-04 18:01:37,499][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:37,501][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:37,503][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:37,505][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:37,507][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:37,509][ldamodel][do_mstep][701]: topic diff=0.003015, rho=0.213201\n",
      "INFO-[2017-05-04 18:01:37,994][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:37,996][ldamodel][update][646]: PROGRESS: pass 21, at document #1/1\n",
      "INFO-[2017-05-04 18:01:38,135][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:38,138][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:38,139][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:38,141][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:38,143][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:38,145][ldamodel][do_mstep][701]: topic diff=0.002330, rho=0.208514\n",
      "INFO-[2017-05-04 18:01:38,588][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:38,590][ldamodel][update][646]: PROGRESS: pass 22, at document #1/1\n",
      "INFO-[2017-05-04 18:01:38,708][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:38,710][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:38,712][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:38,713][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:38,715][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:38,716][ldamodel][do_mstep][701]: topic diff=0.001811, rho=0.204124\n",
      "INFO-[2017-05-04 18:01:39,088][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:39,089][ldamodel][update][646]: PROGRESS: pass 23, at document #1/1\n",
      "INFO-[2017-05-04 18:01:39,207][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:39,209][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:39,210][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:39,212][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:39,213][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:39,214][ldamodel][do_mstep][701]: topic diff=0.001416, rho=0.200000\n",
      "INFO-[2017-05-04 18:01:39,626][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:39,628][ldamodel][update][646]: PROGRESS: pass 24, at document #1/1\n",
      "INFO-[2017-05-04 18:01:39,746][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:39,749][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:39,751][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:39,754][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:39,756][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:39,758][ldamodel][do_mstep][701]: topic diff=0.001113, rho=0.196116\n",
      "INFO-[2017-05-04 18:01:40,187][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:40,188][ldamodel][update][646]: PROGRESS: pass 25, at document #1/1\n",
      "INFO-[2017-05-04 18:01:40,308][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:40,310][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:40,312][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:40,314][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:40,316][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:40,317][ldamodel][do_mstep][701]: topic diff=0.000879, rho=0.192450\n",
      "INFO-[2017-05-04 18:01:40,745][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:40,747][ldamodel][update][646]: PROGRESS: pass 26, at document #1/1\n",
      "INFO-[2017-05-04 18:01:40,897][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:40,899][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:40,902][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:40,904][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:40,906][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:40,908][ldamodel][do_mstep][701]: topic diff=0.000698, rho=0.188982\n",
      "INFO-[2017-05-04 18:01:41,325][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:41,327][ldamodel][update][646]: PROGRESS: pass 27, at document #1/1\n",
      "INFO-[2017-05-04 18:01:41,453][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:41,455][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:41,457][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:41,459][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:41,461][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:41,463][ldamodel][do_mstep][701]: topic diff=0.000557, rho=0.185695\n",
      "INFO-[2017-05-04 18:01:41,866][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:41,868][ldamodel][update][646]: PROGRESS: pass 28, at document #1/1\n",
      "INFO-[2017-05-04 18:01:41,986][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:41,988][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:41,990][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:41,991][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:41,992][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:41,993][ldamodel][do_mstep][701]: topic diff=0.000446, rho=0.182574\n",
      "INFO-[2017-05-04 18:01:42,384][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:42,386][ldamodel][update][646]: PROGRESS: pass 29, at document #1/1\n",
      "INFO-[2017-05-04 18:01:42,504][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:42,506][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:42,508][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:42,509][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:42,511][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:42,512][ldamodel][do_mstep][701]: topic diff=0.000359, rho=0.179605\n",
      "INFO-[2017-05-04 18:01:42,917][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:42,919][ldamodel][update][646]: PROGRESS: pass 30, at document #1/1\n",
      "INFO-[2017-05-04 18:01:43,039][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:43,040][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:43,042][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:43,043][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:43,045][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:43,046][ldamodel][do_mstep][701]: topic diff=0.000290, rho=0.176777\n",
      "INFO-[2017-05-04 18:01:43,430][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:43,431][ldamodel][update][646]: PROGRESS: pass 31, at document #1/1\n",
      "INFO-[2017-05-04 18:01:43,548][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:43,550][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:43,552][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:43,553][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:43,555][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:43,556][ldamodel][do_mstep][701]: topic diff=0.000235, rho=0.174078\n",
      "INFO-[2017-05-04 18:01:43,942][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:43,943][ldamodel][update][646]: PROGRESS: pass 32, at document #1/1\n",
      "INFO-[2017-05-04 18:01:44,063][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:44,065][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:44,066][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:44,068][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:44,069][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:44,071][ldamodel][do_mstep][701]: topic diff=0.000192, rho=0.171499\n",
      "INFO-[2017-05-04 18:01:44,452][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:44,454][ldamodel][update][646]: PROGRESS: pass 33, at document #1/1\n",
      "INFO-[2017-05-04 18:01:44,572][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:44,574][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:44,575][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:44,576][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:44,578][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:44,579][ldamodel][do_mstep][701]: topic diff=0.000156, rho=0.169031\n",
      "INFO-[2017-05-04 18:01:44,988][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:44,990][ldamodel][update][646]: PROGRESS: pass 34, at document #1/1\n",
      "INFO-[2017-05-04 18:01:45,138][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:45,140][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:45,142][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:45,144][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:45,146][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:45,147][ldamodel][do_mstep][701]: topic diff=0.000128, rho=0.166667\n",
      "INFO-[2017-05-04 18:01:45,579][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:45,581][ldamodel][update][646]: PROGRESS: pass 35, at document #1/1\n",
      "INFO-[2017-05-04 18:01:45,728][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:45,730][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:45,732][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:45,734][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:45,736][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:45,737][ldamodel][do_mstep][701]: topic diff=0.000105, rho=0.164399\n",
      "INFO-[2017-05-04 18:01:46,175][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:46,177][ldamodel][update][646]: PROGRESS: pass 36, at document #1/1\n",
      "INFO-[2017-05-04 18:01:46,327][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:46,330][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:46,332][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:46,333][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:46,335][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:46,337][ldamodel][do_mstep][701]: topic diff=0.000087, rho=0.162221\n",
      "INFO-[2017-05-04 18:01:46,785][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:46,787][ldamodel][update][646]: PROGRESS: pass 37, at document #1/1\n",
      "INFO-[2017-05-04 18:01:46,905][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:46,907][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:46,908][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:46,909][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:46,911][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:46,912][ldamodel][do_mstep][701]: topic diff=0.000072, rho=0.160128\n",
      "INFO-[2017-05-04 18:01:47,315][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:47,318][ldamodel][update][646]: PROGRESS: pass 38, at document #1/1\n",
      "INFO-[2017-05-04 18:01:47,435][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:47,437][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:47,439][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:47,440][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:47,441][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:47,443][ldamodel][do_mstep][701]: topic diff=0.000060, rho=0.158114\n",
      "INFO-[2017-05-04 18:01:47,905][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:47,907][ldamodel][update][646]: PROGRESS: pass 39, at document #1/1\n",
      "INFO-[2017-05-04 18:01:48,055][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:48,057][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:48,058][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:48,060][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:48,062][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:48,064][ldamodel][do_mstep][701]: topic diff=0.000050, rho=0.156174\n",
      "INFO-[2017-05-04 18:01:48,490][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:48,492][ldamodel][update][646]: PROGRESS: pass 40, at document #1/1\n",
      "INFO-[2017-05-04 18:01:48,611][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:48,613][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:48,614][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:48,616][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:48,617][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:48,618][ldamodel][do_mstep][701]: topic diff=0.000041, rho=0.154303\n",
      "INFO-[2017-05-04 18:01:48,996][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:48,997][ldamodel][update][646]: PROGRESS: pass 41, at document #1/1\n",
      "INFO-[2017-05-04 18:01:49,118][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:49,120][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:49,122][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:49,123][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:49,124][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:49,125][ldamodel][do_mstep][701]: topic diff=0.000035, rho=0.152499\n",
      "INFO-[2017-05-04 18:01:49,496][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:49,498][ldamodel][update][646]: PROGRESS: pass 42, at document #1/1\n",
      "INFO-[2017-05-04 18:01:49,615][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:49,617][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:49,619][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:49,620][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:49,621][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:49,623][ldamodel][do_mstep][701]: topic diff=0.000029, rho=0.150756\n",
      "INFO-[2017-05-04 18:01:50,127][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:50,129][ldamodel][update][646]: PROGRESS: pass 43, at document #1/1\n",
      "INFO-[2017-05-04 18:01:50,278][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:50,281][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:50,283][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:50,285][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:50,287][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:50,289][ldamodel][do_mstep][701]: topic diff=0.000024, rho=0.149071\n",
      "INFO-[2017-05-04 18:01:50,706][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:50,708][ldamodel][update][646]: PROGRESS: pass 44, at document #1/1\n",
      "INFO-[2017-05-04 18:01:50,825][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:50,827][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:50,828][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:50,830][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:50,831][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:50,833][ldamodel][do_mstep][701]: topic diff=0.000020, rho=0.147442\n",
      "INFO-[2017-05-04 18:01:51,246][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:51,248][ldamodel][update][646]: PROGRESS: pass 45, at document #1/1\n",
      "INFO-[2017-05-04 18:01:51,365][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:51,367][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:51,369][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:51,370][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:51,372][ldamodel][show_topics][798]: topic #4 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"one\" + 0.000*\"go\" + 0.000*\"nigeria\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:51,373][ldamodel][do_mstep][701]: topic diff=0.000017, rho=0.145865\n",
      "INFO-[2017-05-04 18:01:51,790][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:51,792][ldamodel][update][646]: PROGRESS: pass 46, at document #1/1\n",
      "INFO-[2017-05-04 18:01:51,916][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:51,918][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:51,919][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:51,921][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:51,922][ldamodel][show_topics][798]: topic #2 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"it\" + 0.000*\"amp\" + 0.000*\"like\" + 0.000*\"people\" + 0.000*\"new\"\n",
      "INFO-[2017-05-04 18:01:51,923][ldamodel][do_mstep][701]: topic diff=0.000015, rho=0.144338\n",
      "INFO-[2017-05-04 18:01:52,368][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:52,370][ldamodel][update][646]: PROGRESS: pass 47, at document #1/1\n",
      "INFO-[2017-05-04 18:01:52,497][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:52,500][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:52,501][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:52,503][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:52,504][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:52,505][ldamodel][do_mstep][701]: topic diff=0.000012, rho=0.142857\n",
      "INFO-[2017-05-04 18:01:52,932][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:52,934][ldamodel][update][646]: PROGRESS: pass 48, at document #1/1\n",
      "INFO-[2017-05-04 18:01:53,054][ldamodel][show_topics][798]: topic #9 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"mention\" + 0.000*\"it\"\n",
      "INFO-[2017-05-04 18:01:53,056][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:53,057][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:53,058][ldamodel][show_topics][798]: topic #6 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"week\" + 0.000*\"get\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"go\" + 0.000*\"need\" + 0.000*\"new\" + 0.000*\"amp\"\n",
      "INFO-[2017-05-04 18:01:53,060][ldamodel][show_topics][798]: topic #7 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"make\" + 0.000*\"work\" + 0.000*\"need\" + 0.000*\"go\"\n",
      "INFO-[2017-05-04 18:01:53,061][ldamodel][do_mstep][701]: topic diff=0.000010, rho=0.141421\n",
      "INFO-[2017-05-04 18:01:53,459][ldamodel][log_perplexity][527]: -8.484 per-word bound, 358.0 perplexity estimate based on a held-out corpus of 1 documents with 6705 words\n",
      "INFO-[2017-05-04 18:01:53,461][ldamodel][update][646]: PROGRESS: pass 49, at document #1/1\n",
      "INFO-[2017-05-04 18:01:53,606][ldamodel][show_topics][798]: topic #1 (0.100): 0.000*\"u\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"get\" + 0.000*\"new\" + 0.000*\"see\" + 0.000*\"one\" + 0.000*\"life\" + 0.000*\"need\" + 0.000*\"nigerian\"\n",
      "INFO-[2017-05-04 18:01:53,607][ldamodel][show_topics][798]: topic #3 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"like\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"need\" + 0.000*\"see\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:53,609][ldamodel][show_topics][798]: topic #0 (0.100): 0.010*\"u\" + 0.005*\"data\" + 0.005*\"week\" + 0.005*\"get\" + 0.005*\"one\" + 0.004*\"nigeria\" + 0.004*\"like\" + 0.004*\"go\" + 0.004*\"it\" + 0.004*\"new\"\n",
      "INFO-[2017-05-04 18:01:53,610][ldamodel][show_topics][798]: topic #8 (0.100): 0.000*\"u\" + 0.000*\"get\" + 0.000*\"week\" + 0.000*\"one\" + 0.000*\"rt\" + 0.000*\"data\" + 0.000*\"work\" + 0.000*\"life\" + 0.000*\"way\" + 0.000*\"see\"\n",
      "INFO-[2017-05-04 18:01:53,612][ldamodel][show_topics][798]: topic #5 (0.100): 0.000*\"u\" + 0.000*\"week\" + 0.000*\"like\" + 0.000*\"one\" + 0.000*\"data\" + 0.000*\"nigeria\" + 0.000*\"mention\" + 0.000*\"get\" + 0.000*\"rt\" + 0.000*\"life\"\n",
      "INFO-[2017-05-04 18:01:53,613][ldamodel][do_mstep][701]: topic diff=0.000009, rho=0.140028\n"
     ]
    }
   ],
   "source": [
    "# Importing \n",
    "\n",
    "processed = df2.processed.tolist()[0:4]\n",
    "# # Creating the term dictionary of our courpus, where every unique term is assigned an index. dictionary = corpora.Dictionary(doc_clean)\n",
    "dictionary = corpora.Dictionary(processed)\n",
    "# # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in processed]\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=10, id2word = dictionary, passes=50)    \n",
    "for i in ldamodel.print_topics(num_topics=10, num_words=10):print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'complex' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-d9fe9b9b5f75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mviz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_term_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pyLDAvis/_display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(data, local, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd3_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ldavis_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ldavis_css_url'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_ipynb_local_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_data_to_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m def show(data, ip='127.0.0.1', port=8888, n_retries=50,\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pyLDAvis/_display.py\u001b[0m in \u001b[0;36mprepared_data_to_html\u001b[0;34m(data, d3_url, ldavis_url, ldavis_css_url, template_type, visid, use_http)\u001b[0m\n\u001b[1;32m    176\u001b[0m                            \u001b[0md3_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md3_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                            \u001b[0mldavis_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mldavis_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                            \u001b[0mvis_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                            ldavis_css_url=ldavis_css_url)\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mto_json\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNumPyEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pyLDAvis/utils.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'complex' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "viz = pyLDAvis.gensim.prepare(ldamodel, doc_term_matrix, dictionary)\n",
    "pyLDAvis.display(viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.062*\"sister\" + 0.062*\"driving\" + 0.061*\"father\"')\n",
      "(1, '0.067*\"sugar\" + 0.038*\"cause\" + 0.038*\"stress\"')\n",
      "(2, '0.054*\"sister\" + 0.054*\"father\" + 0.054*\"better.\"')\n"
     ]
    }
   ],
   "source": [
    "# Importing Gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "doc1 = \"Sugar is bad to consume. My sister likes to have sugar, but not my father.\"\n",
    "doc2 = \"My father spends a lot of time driving my sister around to dance practice.\"\n",
    "doc3 = \"Doctors suggest that driving may cause increased stress and blood pressure.\"\n",
    "doc4 = \"Sometimes I feel pressure to perform well at school, but my father never seems to drive my sister to do better.\"\n",
    "doc5 = \"Health experts say that Sugar is not good for your lifestyle.\"\n",
    "\n",
    "# compile documents\n",
    "doc_complete = [doc1, doc2, doc3, doc4, doc5]\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    doc = \" \".join([i for i in doc.lower().split() if i not in stop.union(exclude)])\n",
    "    doc = \" \".join(lemma.lemmatize(word) for word in doc.split())\n",
    "    return doc\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in doc_complete] \n",
    "\n",
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel2 = Lda(doc_term_matrix, num_topics=3, id2word = dictionary, passes=50)\n",
    "for i in ldamodel2.print_topics(num_topics=3, num_words=3): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-7d4dc63bfcff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# I had added all the handles I could think of in one category and then gathered the tweets.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Not the best way to go about it! To add new handles to a category, simply use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetUserTimeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# and add that under the relevant category with the handle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpycon_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpycon_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Business & CEOs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api' is not defined"
     ]
    }
   ],
   "source": [
    "def getTweets(category_dict, category): \n",
    "    \"\"\" Function to get the tweets for each handle in the dictionary in the particular category. Parameters: ---------- category_dict: User category dictionary consisting of categories and user handles. category: String. Name of the category. Returns: ------- category_dict: Dictionary with the most recent 200 tweets of all user handles. \"\"\" \n",
    "    for handle in category_dict[category]: \n",
    "        category_dict[category][handle] = api.GetUserTimeline(screen_name=handle, count=200) \n",
    "        return category_dict\n",
    "\n",
    "# I had added all the handles I could think of in one category and then gathered the tweets. \n",
    "# Not the best way to go about it! To add new handles to a category, simply use \n",
    "api.GetUserTimeline(screen_name=handle) \n",
    "# and add that under the relevant category with the handle\n",
    "pycon_dict = getTweets(pycon_dict, 'Business & CEOs')\n",
    "pickle.dump(pycon_dict, open('pycon_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
